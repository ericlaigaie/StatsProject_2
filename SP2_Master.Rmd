---
title: "SP2_Master"
author: "Eric Laigaie"
date: "3/28/2022"
output: html_document
---

Loading in packages
```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(ggplot2)
library(GGally)
library(ggpubr)
library(MASS)
library(car)
library(caret)
library(ROCR)
library(glmnet)
library(corrplot)
library(RColorBrewer)
library(pheatmap)
library(psych)


```

### Data is stored in a .data and .test file. Let's read them as .csvs & define the column names.
```{r}
df_train <- read.csv("https://raw.githubusercontent.com/ericlaigaie/StatsProject_2/main/train.csv")
df_test <- read.csv("https://raw.githubusercontent.com/ericlaigaie/StatsProject_2/main/test.csv")
```

### A) Clean table and check for typos and NAs
### A.1) Fix Response Typo.  Only in test.
```{r}
# Just realized the pay_response variable is stored as '<=50K.' and '>50K.'. Let's get rid of those periods
df_test <- df_test %>% mutate(pay_response = ifelse(pay_response == '<=50K.', '<=50K', '>50K'))
```

### A.2) Check for NA's
```{r}
#check for number of null values in data
sapply(df_train, function(x) sum(is.na(x)))
sapply(df_test, function(x) sum(is.na(x)))

```

### A.3)summary tables
```{r}
#create summary
summary(df_train)
str(df_train)
summary(df_test)
str(df_test) # Update this from train to test.

#count number of levels
levelcount <- as.data.frame(t(df_train%>% summarise_all(n_distinct)))
colnames(levelcount) <- c('Level Count')
print(levelcount)

#added code to count the levels for test.
levelcount_tst <- as.data.frame(t(df_test%>% summarise_all(n_distinct)))
colnames(levelcount_tst) <- c('Level Count')
print(levelcount_tst)

```

### A.4) Check ? Counts
```{r}
# No ?'s in education, marital_status, relationship, race, sex, pay_response

print(paste('Train - ? Working Class:', nrow(df_train %>% filter(workclass == '?')), sep=' '))
print(paste('Train - ? Occupation:', nrow(df_train %>% filter(occupation == '?')), sep=' '))
print(paste('Train - ? Native Country:', nrow(df_train %>% filter(native_country == '?')), sep=' '))

print(paste('Test  - ? Working Class:', nrow(df_test %>% filter(workclass == '?')), sep=' '))
print(paste('Test  - ? Occupation:', nrow(df_test %>% filter(occupation == '?')), sep=' '))
print(paste('Test  - ? Native Country:', nrow(df_test %>% filter(native_country == '?')), sep=' '))
```
### A.5) Removing ? from Train and Test
```{r}
# Let's make a version 2 of train and test that has no ?'s
df_train2 <- df_train %>% filter(workclass != '?')
df_train2 <- df_train2 %>% filter(occupation != '?')
df_train2 <- df_train2 %>% filter(native_country != '?')

df_test2 <- df_test %>% filter(workclass != '?')
df_test2 <- df_test2 %>% filter(occupation != '?')
df_test2 <- df_test2 %>% filter(native_country != '?')

#Created 2 new dataframes: df_train2 and df_test2
```

### A.6) Change all strings to factors
```{r}
df_train2 <- as.data.frame(unclass(df_train2), stringsAsFactors = TRUE)
df_test2 <- as.data.frame(unclass(df_test2), stringsAsFactors = TRUE)
```


```{r}


#Gather the counts of the response variables in each dataset

describe(df_train2)

# Count of <=50K and >50K
sum(with(df_train2,pay_response == "<=50K")) # 22654
sum(with(df_train2,pay_response == ">50K")) #7508

sum(with(df_test2,pay_response == "<=50K")) #11360
sum(with(df_test2,pay_response == ">50K")) #3700


```


###EDA Exploratory Data Analysis
###Will look for multicollinearity, ways to reduce levels in our categorical responses and removing columns in our clean output.

###This section check correlation of continous values
```{r}
# Find all numeric variables in cleaned dataset
numericVars <- which(sapply(df_train2, is.numeric))

# Create df of numeric categories only
both_numVar <- df_train2[, numericVars]

#correlations of numeric variables
cor_numVar <- cor(both_numVar, use="pairwise.complete.obs")

#Sort by decreasing correlations with MSRP
cor_sorted <- as.matrix(sort(cor_numVar[,'age'], decreasing = TRUE))

# Select only high correlations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.01)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]

# Plot correlations
corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt")

#We observe no correlation among the continuous variables
```
###Heat Map to check clusters
```{r}

#cluster.train.x <- df_train2[,c(2,4,6,12,13,14)]
#cluster.train.y <- df_train2$pay_response
#cluster.train.y <- as.factor(as.character(cluster.train.y))

df_train_phmap <- as.data.frame(unclass(df_train2), stringsAsFactors = TRUE)
cluster.train.x <- df_train_phmap[,c(2,4,12,13,14)]
cluster.train.y <- df_train2$pay_response

cols <- colorRampPalette(brewer.pal(9, "Set1"))
x<-t(cluster.train.x)
pos_df = data.frame("Pay" = cluster.train.y)
colnames(x) <- rownames(pos_df)

#pheatmap(x,cluster_rows = F, annotation_col=data.frame("Pay"=cluster.train.y),annotation_colors=list("Pay"=c("<=50K"="white",">50K"="green")),scale="row",legend=T,color=colorRampPalette(c("blue","white", "red"), space = "rgb")(30000))

pheatmap(x,cluster_rows = T, annotation_col=pos_df,annotation_colors=list("Pay"=c("<=50K"="white",">50K"="green")),scale="row",legend=T,color=colorRampPalette(c("blue","white", "red"), space = "rgb")(30000))


```
### Check large factors - education



```{r}
# Let's try and see if we can collapse some levels of the education factor

# First, look at train ----------------------------------------------------------------------------------------------------


# Establish factor order
edu_levels <- c('Preschool','1st-4th','5th-6th','7th-8th','9th','10th','11th','12th','HS-grad','Some-college','Assoc-voc','Assoc-acdm','Bachelors','Masters','Prof-school','Doctorate')
df_train2 <- df_train2 %>%
  mutate(education = fct_relevel(education, edu_levels))

# Plot pay_response proportion by level
ggplot(df_train2, aes(y=education, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Education - Train')

# New levels of factors (any unlisted here are staying single)
grades <- c('1st-4th','5th-6th','7th-8th','9th','10th','11th','12th')
grads <- c('HS-grad','Some-college')
assocs <- c('Assoc-voc','Assoc-acdm')
docs <- c('Prof-school','Doctorate')

# Mutate education factor into new levels
df_trainclean <- df_train2 %>% mutate(
  education = case_when(
      education == 'Preschool' ~ 'Preschool',
      education %in% grades ~ 'Grade School',
      education %in% grads ~ 'HS Grads',
      education %in% assocs ~ 'Assocs',
      education == 'Bachelors' ~ 'Bachelors',
      education == 'Masters' ~ 'Masters',
      education %in% docs ~ 'Docs/Profs'
    )
)

# Establish new factor order
edu_levels <- c('Preschool', 'Grade School', 'HS Grads', 'Assocs', 'Bachelors', 'Masters', 'Docs/Profs')
df_trainclean <- df_trainclean %>% mutate(education = factor(education), education = fct_relevel(education, edu_levels))
  
# Plot final levels
ggplot(df_trainclean, aes(y=education, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Education - Train')

# Repeat process with test ----------------------------------------------------------------------------------------------
edu_levels <- c('Preschool','1st-4th','5th-6th','7th-8th','9th','10th','11th','12th','HS-grad','Some-college','Assoc-voc','Assoc-acdm','Bachelors','Masters','Prof-school','Doctorate')
df_test2 <- df_test2 %>%
  mutate(education = fct_relevel(education, edu_levels))

# Plot pay_response proportion by level
ggplot(df_test2, aes(y=education, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Education - Test')

# While the distributions here are slightly different, let's keep the same groups
grades <- c('1st-4th','5th-6th','7th-8th','9th','10th','11th','12th')
grads <- c('HS-grad','Some-college')
assocs <- c('Assoc-voc','Assoc-acdm')
docs <- c('Prof-school','Doctorate')

# Mutate education factor into new levels
df_testclean <- df_test2 %>% mutate(
  education = case_when(
      education == 'Preschool' ~ 'Preschool',
      education %in% grades ~ 'Grade School',
      education %in% grads ~ 'HS Grads',
      education %in% assocs ~ 'Assocs',
      education == 'Bachelors' ~ 'Bachelors',
      education == 'Masters' ~ 'Masters',
      education %in% docs ~ 'Docs/Profs'
    )
)

# Establish new factor order
edu_levels <- c('Preschool', 'Grade School', 'HS Grads', 'Assocs', 'Bachelors', 'Masters', 'Docs/Profs')
df_testclean <- df_testclean %>% mutate(education = factor(education), education = fct_relevel(education, edu_levels))
  
# Plot final levels
ggplot(df_testclean, aes(y=education, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Education - Test')


#Response variable (>50K) increases as the level of school increases!
```

### Check large factors - workclass
```{r workclass, fig.width=10, fig.height=6}
ggarrange(
ggplot(df_train2, aes(y=workclass, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Workclass - Train') + theme(legend.position='none'),
ggplot(df_test2, aes(y=workclass, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Workclass - Test') + theme(legend.position='none'),
nrow=1)
# There aren't too many levels here, and I can't find any pair I would really like to collapse together.
#Rayon - I agree with this. no clear way of collapsing it.All Workclass included our variable of interest. Exception is Without Pay in Training

#based on the original response for government workclass, we will group local, state and Fed into Government
df_trainclean$workclass <- recode_factor(df_trainclean$workclass, 
                                         `State-gov` = "Government", 
                                         `Local-gov` = "Government", 
                                         `Federal-gov` = "Government")
df_testclean$workclass <- recode_factor(df_testclean$workclass, 
                                         `State-gov` = "Government", 
                                         `Local-gov` = "Government", 
                                         `Federal-gov` = "Government")

#Visual of new workclass plot
ggarrange(
ggplot(df_trainclean, aes(y=workclass, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Workclass - Train') + theme(legend.position='none'),
ggplot(df_testclean, aes(y=workclass, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by Workclass - Test') + theme(legend.position='none'),
nrow=1)

```

### Check large factors - occupation
```{r occupation, fig.width=10, fig.height=6}
ggarrange(
ggplot(df_train2, aes(y=occupation, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by occupation - Train') + theme(legend.position='none'),
ggplot(df_test2, aes(y=occupation, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by occupation - Test') + theme(legend.position='none'),
nrow=1)
# While there are a lot of levels here, I don't see any groups that would make sense to collapse together.
```

### Check large factors - marital_status
```{r marital_status, fig.width=10, fig.height=6}
ggarrange(
ggplot(df_train2, aes(y=marital_status, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by marital_status - Train') + theme(legend.position='none'),
ggplot(df_test2, aes(y=marital_status, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by marital_status - Test') + theme(legend.position='none'),
nrow=1)
# There's not a ton of levels and I don't see any groups that would make sense to collapse together.
# Rayon I agree

#based on the original responses we observed similar response portions for 1) married with spouse and 2) single who was once married
#we will group the following 1) Married-spouse = Married-civ-spouse + Married-af-spouse 2) Single_was-married = Widowed, separated, divorced
df_trainclean$marital_status <- recode_factor(df_trainclean$marital_status, 
                                         `Widowed` = "Single-was-married", 
                                         `Separated` = "Single-was-married", 
                                         `Divorced` = "Single-was-married",
                                         `Married-AF-spouse` = "Married",
                                         `Married-civ-spouse` = "Married")
df_testclean$marital_status <- recode_factor(df_testclean$marital_status, 
                                         `Widowed` = "Single-was-married", 
                                         `Separated` = "Single-was-married", 
                                         `Divorced` = "Single-was-married",
                                         `Married-AF-spouse` = "Married",
                                         `Married-civ-spouse` = "Married")


#View new marital status levels responses
ggarrange(
ggplot(df_trainclean, aes(y=marital_status, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by marital_status - Train') + theme(legend.position='none'),
ggplot(df_testclean, aes(y=marital_status, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by marital_status - Test') + theme(legend.position='none'),
nrow=1)


```

### Check large factors - native_country
```{r}
# First, let's look at train ---------------------------------------------------------------------------------------------

ggplot(df_train2, aes(y=native_country, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by native_country - Train')

# There are way too many levels here to keep. The most logical way to collapse these would be by continent
# Grouping by asia, europe, north america, and latin america, we are left with Outlying-US territories and 'South' -- this could be South Africa or South Korea...it is also weird that there are no African countries.

asia <- c('Cambodia','China','Hong','India','Iran','Japan','Laos','Philippines','Taiwan','Thailand','Vietnam')
europe <- c('England','France','Germany','Greece','Holand-Netherlands','Hungary','Ireland','Italy','Poland','Portugal','Scotland','Yugoslavia')
namerica <- c('Canada','United-States')
lamerica <- c('Cuba','Dominican-Republic','El-Salvador','Guatemala','Haiti','Honduras','Jamaica','Mexico','Nicaragua','Puerto-Rico','Trinadad&Tobago','Columbia','Ecuador','Peru')
islands <- c('Outlying-US(Guam-USVI-etc)')

df_trainclean <- df_trainclean %>% mutate(
  native_country = case_when(
      native_country %in% asia ~ 'Asia',
      native_country %in% europe ~ 'Europe',
      native_country %in% namerica ~ 'North America',
      native_country %in% lamerica ~ 'Latin America',
      native_country %in% islands ~ 'US Territories',
      TRUE ~ 'South'
    )
)

ggplot(df_trainclean, aes(y=native_country, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by native_country - Train')

# Next, let's look at test -----------------------------------------------------------------------------------------------

ggplot(df_test2, aes(y=native_country, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by native_country - test')

# There are way too many levels here to keep. The most logical way to collapse these would be by continent
# Grouping by asia, europe, north america, and latin america, we are left with Outlying-US territories and 'South' -- this could be South Africa or South Korea...it is also weird that there are no African countries.

asia <- c('Cambodia','China','Hong','India','Iran','Japan','Laos','Philippines','Taiwan','Thailand','Vietnam')
europe <- c('England','France','Germany','Greece','Holand-Netherlands','Hungary','Ireland','Italy','Poland','Portugal','Scotland','Yugoslavia')
namerica <- c('Canada','United-States')
lamerica <- c('Cuba','Dominican-Republic','El-Salvador','Guatemala','Haiti','Honduras','Jamaica','Mexico','Nicaragua','Puerto-Rico','Trinadad&Tobago','Columbia','Ecuador','Peru')
islands <- c('Outlying-US(Guam-USVI-etc)')

df_testclean <- df_testclean %>% mutate(
  native_country = case_when(
      native_country %in% asia ~ 'Asia',
      native_country %in% europe ~ 'Europe',
      native_country %in% namerica ~ 'North America',
      native_country %in% lamerica ~ 'Latin America',
      native_country %in% islands ~ 'US Territories',
      TRUE ~ 'South'
    )
)

ggplot(df_testclean, aes(y=native_country, fill=pay_response)) + geom_bar(position='fill') + labs(x='pay_response proportion', title='Pay_response Proportions by native_country - test')
```

### Capital Gain & Capital Loss
```{r}
# We found that no person has nonzero gain and loss (figured as much), so how can we calculate cap_net?
df_train2 %>% filter(capital_gain != 0 & capital_loss != 0)
df_test2 %>% filter(capital_gain != 0 & capital_loss != 0)

# Since we know that cap_gain and cap_loss cannot exist together, simply calculating cap_gain - cap_loss would give us what we want...two possible cases:
#   Capital_gain exists: Capital_net = X - 0
#   Capital_loss exists: Capital_net = 0 - X

df_trainclean$capital_net = df_trainclean$capital_gain - df_trainclean$capital_loss
df_testclean$capital_net = df_testclean$capital_gain - df_testclean$capital_loss

df_trainclean <- dplyr::select(df_trainclean,-c(capital_gain, capital_loss))
df_testclean <- dplyr::select(df_testclean,-c(capital_gain, capital_loss))

```

### Education & Education_Num
```{r}
# Let's check for multicollinearity

ggplot(df_trainclean, aes(y=education, x=education_num)) + geom_boxplot(fill='indianred2') + labs(title='Education_num distribution by Education - Train') + scale_y_discrete("education", limits = c("Preschool" , "Grade School", "HS Grads", "Assocs", "Bachelors" , "Masters" , "Docs/Profs"))

ggplot(df_testclean, aes(y=education, x=education_num)) + geom_boxplot(fill='indianred2') + labs(title='Education_num distribution by Education - Test') + scale_y_discrete("education", limits = c("Preschool" , "Grade School", "HS Grads", "Assocs", "Bachelors" , "Masters" , "Docs/Profs"))

# Here, you can see that these two variables are directly related, as expected...so we can only include one. Since education is best viewed through factors (there isn't a numerical relationship between education levels), we'll keep education.

df_trainclean <- dplyr::select(df_trainclean,-c(education_num))
df_testclean <- dplyr::select(df_testclean,-c(education_num))
```

### Plot Matrix
```{r}
ggpairs(df_trainclean, columns = c(2,4,11,14), ggplot2::aes(colour=pay_response))

ggpairs(df_testclean, columns = c(2,4,11,14), ggplot2::aes(colour=pay_response))
#DY - what is this used for?
#Answer(Rayon) - Looking for Multicollinearity among the continuous variables.
```

### Response Variable Balance
```{r}
print(paste('Percentage of positive responses in Train: ',
            round((nrow(df_train2 %>% filter(pay_response == '>50K')) / nrow(df_train2)) * 100,2),
            '%', sep=''))
print(paste('Percentage of positive responses in Test: ',
            round((nrow(df_test2 %>% filter(pay_response == '>50K')) / nrow(df_test2)) * 100,2),
            '%', sep=''))

```

### What's Next?
1. We should look through the factor variables for any evidence of collinearity.

```{r workclass vs. education}



t(aggregate(workclass~education,data=df_trainclean,summary))
count <- table(df_trainclean$workclass, df_trainclean$education)
plot(count, col=c("plum2","light green", "green", "papayawhip", "brown", off = 20))


#Observed a slight collinearity among the workclass and education variables.

```




```{r maritalstatus vs education}


t(aggregate(marital_status~education,data=df_trainclean,summary))

count <- t(table(df_trainclean$marital_status, df_trainclean$education))
plot(count, col=c("plum2","light green", "green", "papayawhip", off = 20))

#Didn't observe any collinearity among the maritalstatus and education variables.

```

```{r Race vs education}

t(aggregate(race~education,data=df_trainclean,summary))
count <- t(table(df_trainclean$race, df_trainclean$education))
plot(count, col=c("plum2","light green", "green", "papayawhip", "brown","purple", off = 20))


# Observed no multicollinearity among the variables race and education
# We observe race is heavily skewed to race=White 
```

```{r race vs Marital status}

count <- t(table(df_trainclean$race, df_trainclean$marital_status))
plot(count, col=c("plum2","light green", "green", "papayawhip", "brown", off = 20))

#Slight evidence of collinearity among race and marital status. However, there were more observations for White (85%) than other races in the data.

df_trainclean %>% group_by(race) %>% summarise(count = n())


```

```{r relationship and Marital status}

#Count of relationship vs. Marital Status
count <- t(table(df_trainclean$relationship, df_trainclean$marital_status))
plot(count, col=c("plum2","light green", "green", "papayawhip", "brown","purple", off = 20))

# There is strong evidence of collinearity between race and marital status.


```

```{r}
df_trainclean %>% group_by(race, occupation) %>% summarise(count = n())

```

```{r}

#creating two new variable for LDA
#df_trainclean_lda <- df_trainclean
#df_testclean_lda <- df_testclean

# Remove fnlwgt --- Doesn't make sense logically and Turner said it was okay - Eric
df_trainclean <- df_trainclean %>% dplyr::select(-fnlwgt)
df_testclean <- df_testclean %>% dplyr::select(-fnlwgt)

df_trainclean <- df_trainclean %>% dplyr::select(-id)
df_testclean <- df_testclean %>% dplyr::select(-id)

df_trainclean <- df_trainclean %>% dplyr::select(-relationship)
df_testclean <- df_testclean %>% dplyr::select(-relationship)
```



2. We should consider if variables make sense to include in the model (fnlwgt).

### Objective 1 - Stepwise & LASSO Models
```{r}
# Full Dataset - Stepwise Model
full.log<-glm(pay_response~.,family="binomial",data=df_trainclean)
step.log<-full.log %>% stepAIC(trace=FALSE)

# Check Cook's Distance
Step.cd <- cooks.distance(step.log)
idx <- which(Step.cd >1) # row numbers
Step.cd[idx]

# All good here

# Summary of model
summary(step.log)
coef(step.log)
vif(step.log)

# Odds ratios of model
exp(cbind("Odds ratio" = coef(step.log), confint.default(step.log, level = 0.95)))

# Make predictions on model
fit.pred.step<-predict(step.log,newdata=df_testclean,type="response")

# Set cutoff and make classifications from predictions
cutoff<- 0.5
class.step<-factor(ifelse(fit.pred.step>cutoff,">50K","<=50K"),levels=c("<=50K",">50K"))

# Print confusion matrix
conf.step<-table(class.step,df_testclean$pay_response)
cm.step <- confusionMatrix(conf.step)
cm.step

# Test different cutoffs - create vectors to store cutoffs and accuracies
step.cutoffs <- seq(.1,.9,.01)
step.accuracies <- c()

# Loop through cutoffs and find confusion matrix and accuracy of new classifications
for (i in step.cutoffs) {
  curr.class.step <- factor(ifelse(fit.pred.step>i,">50K","<=50K"),levels=c("<=50K",">50K"))
  curr.conf.step <- table(curr.class.step,df_testclean$pay_response)
  curr.cm.step <- confusionMatrix(curr.conf.step)
  
  step.accuracies <- append(step.accuracies, 100*curr.cm.step$overall[1])
}

# Create dataframe from vectors and establish max value for each column
step.cutoff_acc_loop <- data.frame('cutoffs' = step.cutoffs, 'accuracies' = step.accuracies)
step.maxacc <- max(step.cutoff_acc_loop$accuracies)
step.maxcut <- step.cutoff_acc_loop %>% filter(accuracies == step.maxacc) %>% pull(cutoffs)
step.maxcut <- step.maxcut[1]

# Create accuracy geom_line chart and mark maximum accuracy
ggplot(step.cutoff_acc_loop, aes(x=cutoffs, y=accuracies, label=accuracies)) + 
  geom_line(size=2, color='indianred2') +
  labs(x='Classiciation Cutoff', y='Accuracy', title='Accuracy by Cutoff Value - Stepwise') +
  geom_point(aes(y=step.maxacc, x=step.maxcut), size=5, color='black') +
  geom_text(
    aes(label=
          ifelse(cutoffs == step.maxcut,
                 paste(round(accuracies,2),'%, cutoff = ',step.maxcut,sep='')
                 ,'')
        ),hjust=-.2, vjust=0
    )
```

```{r}
# We have an idea to cut out occupation because it's similar to workclass and has many levels that decreases interpretability

# We feel like Occupation and Workclass are similar, and one could be removed....let's try Occupation
df_trainclean_noocc <- df_trainclean %>% dplyr::select(-occupation)
df_testclean_noocc <- df_testclean %>% dplyr::select(-occupation)

# No_Occ Dataset - Stepwise Model
No_Occ.log<-glm(pay_response~.,family="binomial",data=df_trainclean_noocc)
No_Occ.step.log<-No_Occ.log %>% stepAIC(trace=FALSE)

# Check Cook's Distance
No_Occ.cd <- cooks.distance(No_Occ.step.log)
idx <- which(No_Occ.cd >1)
No_Occ.cd[idx]

# All good here

# Summary of model
summary(No_Occ.step.log)
coef(No_Occ.step.log)
vif(No_Occ.step.log)

# Odds ratios of model
exp(cbind("Odds ratio" = coef(No_Occ.step.log), confint.default(No_Occ.step.log, level = 0.95)))

# Make predictions on model
No_Occ.fit.pred.step<-predict(No_Occ.step.log,newdata=df_testclean_noocc,type="response")

# Set cutoff and make classifications from predictions
cutoff<- 0.5
No_Occ.class.step<-factor(ifelse(No_Occ.fit.pred.step>cutoff,">50K","<=50K"),levels=c("<=50K",">50K"))

# Print confusion matrix
No_Occ.conf.step<-table(No_Occ.class.step,df_testclean_noocc$pay_response)
No_Occ.cm.step <- confusionMatrix(No_Occ.conf.step)
No_Occ.cm.step

# Test different cutoffs - create vectors to store cutoffs and accuracies
step.cutoffs <- seq(.1,.9,.01)
No_Occ.step.accuracies <- c()

# Loop through cutoffs and find confusion matrix and accuracy of new classifications
for (i in step.cutoffs) {
  curr.class.step <- factor(ifelse(No_Occ.fit.pred.step>i,">50K","<=50K"),levels=c("<=50K",">50K"))
  curr.conf.step <- table(curr.class.step,df_testclean$pay_response)
  curr.cm.step <- confusionMatrix(curr.conf.step)
  
  No_Occ.step.accuracies <- append(No_Occ.step.accuracies, 100*curr.cm.step$overall[1])
}

# Create dataframe from vectors and establish max value for each column
No_Occ.step.cutoff_acc_loop <- data.frame('cutoffs' = step.cutoffs, 'accuracies' = No_Occ.step.accuracies)
No_Occ.step.maxacc <- max(No_Occ.step.cutoff_acc_loop$accuracies)
No_Occ.step.maxcut <- No_Occ.step.cutoff_acc_loop %>% filter(accuracies == No_Occ.step.maxacc) %>% pull(cutoffs)
No_Occ.step.maxcut <- No_Occ.step.maxcut[1]

# Create accuracy geom_line chart and mark maximum accuracy
ggplot(No_Occ.step.cutoff_acc_loop, aes(x=cutoffs, y=accuracies, label=accuracies)) + 
  geom_line(size=2, color='indianred2') +
  labs(x='Classiciation Cutoff', y='Accuracy', title='Accuracy by Cutoff Value - Stepwise') +
  geom_point(aes(y=No_Occ.step.maxacc, x=No_Occ.step.maxcut), size=5, color='black') +
  geom_text(
    aes(label=
          ifelse(cutoffs == No_Occ.step.maxcut,
                 paste(round(accuracies,2),'%, cutoff = ',No_Occ.step.maxcut,sep='')
                 ,'')
        ),hjust=-.2, vjust=0
    )
```

```{r}
# Here, we can see that removing occupation does little to no damage on the model, but increases interpretability by a lot. One important variable to note is education...no levels are significant.

# Let's prepare a ROC curve for both models
# Prepare Step ROC Curve
full.results.step<-prediction(fit.pred.step, df_testclean$pay_response,label.ordering=c("<=50K",">50K"))
full.roc.step = performance(full.results.step, measure = "tpr", x.measure = "fpr")

# Prepare NoOcc Step ROC Curve
No_Occ.results.step<-prediction(No_Occ.fit.pred.step, df_testclean_noocc$pay_response,label.ordering=c("<=50K",">50K"))
No_Occ.roc.step = performance(No_Occ.results.step, measure = "tpr", x.measure = "fpr")

plot(full.roc.step, main='Stepwise ROC Curves - Full & No_Occ')
plot(No_Occ.roc.step,col="orange", add = TRUE)
legend("bottomright",legend=c("Full Stepwise","No_Occ Stepwise"),col=c("blue", "orange"),lty=1,lwd=1)
abline(a=0, b= 1)
```

```{r}
# Prepare matrices
dat.train.x <- model.matrix(pay_response~.-1,df_trainclean)
dat.train.y<-df_trainclean[,10]

# Do cross-validation and plot
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
print("CV Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#Optimal penalty
print("Penalty Value:")
cvfit$lambda.min

#For final model predictions go ahead and refit lasso using entire
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)

finalmodel$beta

#Test set predictions & confusion matrix
dat.test.x<-model.matrix(pay_response~.-1,df_testclean)
fit.pred.lasso <- predict(finalmodel, newx = dat.test.x, type = "response")

# Set cutoff and make classifications off of predictions
cutoff<-0.5
class.lasso<-factor(ifelse(fit.pred.lasso>cutoff,">50K","<=50K"),levels=c("<=50K",">50K"))

#Confusion Matrix for Lasso
conf.lasso<-table(class.lasso,df_testclean$pay_response)
confusionMatrix(conf.lasso)

# Test different cutoffs - create vectors to store cutoffs and accuracies
lasso.cutoffs <- seq(.1,.9,.01)
lasso.accuracies <- c()

# Loop through cutoffs and find confusion matrix and accuracy of new classifications
for (i in lasso.cutoffs) {
  curr.class.lasso <- factor(ifelse(fit.pred.lasso>i,">50K","<=50K"),levels=c("<=50K",">50K"))
  curr.conf.lasso <- table(curr.class.lasso,df_testclean$pay_response)
  curr.cm.lasso <- confusionMatrix(curr.conf.lasso)
  
  lasso.accuracies <- append(lasso.accuracies, 100*curr.cm.lasso$overall[1])
}

# Create dataframe from vectors and establish max value for each column
lasso.cutoff_acc_loop <- data.frame('cutoffs' = lasso.cutoffs, 'accuracies' = lasso.accuracies)
lasso.maxacc <- max(lasso.cutoff_acc_loop$accuracies)
lasso.maxcut <- lasso.cutoff_acc_loop %>% filter(accuracies == lasso.maxacc) %>% pull(cutoffs)

# Create accuracy geom_line chart and mark maximum accuracy
ggplot(lasso.cutoff_acc_loop, aes(x=cutoffs, y=accuracies, label=accuracies)) + 
  geom_line(size=2, color='indianred2') +
  labs(x='Classiciation Cutoff', y='Accuracy', title='Accuracy by Cutoff Value - lassowise') +
  geom_point(aes(y=lasso.maxacc, x=lasso.maxcut), size=5, color='black') +
  geom_text(
    aes(label=
          ifelse(accuracies == lasso.maxacc,
                 paste(round(accuracies,2),'%, cutoff = ',lasso.maxcut,sep='')
                 ,'')
        ),hjust=-.2, vjust=0
    )
```

```{r}
# Prepare LASSO ROC Curve
results.lasso<-prediction(fit.pred.lasso, df_testclean$pay_response,label.ordering=c("<=50K",">50K"))
roc.lasso = performance(results.lasso, measure = "tpr", x.measure = "fpr")

# Prepare Step ROC Curve
results.step<-prediction(fit.pred.step, df_testclean$pay_response,label.ordering=c("<=50K",">50K"))
roc.step = performance(results.step, measure = "tpr", x.measure = "fpr")

plot(roc.lasso)
plot(roc.step,col="orange", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise"),col=c("blue", "orange"),lty=1,lwd=1)
abline(a=0, b= 1)
```

#Objective 2
#Complex variables to see if model improves

# Interaction Model
```{r}
# Build Interaction Model
fit.int <- glm(pay_response ~ hours_per_week + capital_net + age*capital_net + age:sex + race:age + age:marital_status + native_country:age + marital_status:hours_per_week + occupation:sex + age:occupation, family='binomial', data=df_trainclean)

# Check Cook's Distance
fit.int.cd <- cooks.distance(fit.int)
idx <- which(fit.int.cd >1) # row numbers
fit.int.cd[idx]

# All good here

# Model Summary
summary(fit.int)
#confint(fit.int)

# Make predictions on model
fit.pred.int<-predict(fit.int,newdata=df_testclean,type="response")

# Set cutoff and make classifications from predictions
cutoff<- 0.48
class.int<-factor(ifelse(fit.pred.int>cutoff,">50K","<=50K"),levels=c("<=50K",">50K"))

# Print confusion matrix
conf.int<-table(class.int,df_testclean$pay_response)
cm.int <- confusionMatrix(conf.int)
cm.int

# Test different cutoffs - create vectors to store cutoffs and accuracies
int.cutoffs <- seq(.1,.9,.01)
int.accuracies <- c()

# Loop through cutoffs and find confusion matrix and accuracy of new classifications
for (i in int.cutoffs) {
  curr.class.int <- factor(ifelse(fit.pred.int>i,">50K","<=50K"),levels=c("<=50K",">50K"))
  curr.conf.int <- table(curr.class.int,df_testclean$pay_response)
  curr.cm.int <- confusionMatrix(curr.conf.int)
  
  int.accuracies <- append(int.accuracies, 100*curr.cm.int$overall[1])
}

# Create dataframe from vectors and establish max value for each column
int.cutoff_acc_loop <- data.frame('cutoffs' = int.cutoffs, 'accuracies' = int.accuracies)
int.maxacc <- max(int.cutoff_acc_loop$accuracies)
int.maxcut <- int.cutoff_acc_loop %>% filter(accuracies == int.maxacc) %>% pull(cutoffs)
int.maxcut <- int.maxcut[1]

# Create accuracy geom_line chart and mark maximum accuracy
ggplot(int.cutoff_acc_loop, aes(x=cutoffs, y=accuracies, label=accuracies)) + 
  geom_line(size=2, color='indianred2') +
  labs(x='Classiciation Cutoff', y='Accuracy', title='Accuracy by Cutoff Value - Interaction Based') +
  geom_point(aes(y=int.maxacc, x=int.maxcut), size=5, color='black') +
  geom_text(
    aes(label=
          ifelse(cutoffs == int.maxcut,
                 paste(round(accuracies,2),'%, cutoff = ',int.maxcut,sep='')
                 ,'')
        ),hjust=-.2, vjust=0
    )

# Prepare Step ROC Curve
results.int<-prediction(fit.pred.int, df_testclean$pay_response,label.ordering=c("<=50K",">50K"))
roc.int = performance(results.int, measure = "tpr", x.measure = "fpr")

plot(roc.int, col='Orange', main='ROC Model - Interaction Model')
legend("bottomright",legend=c('Interaction Model'),col=c("orange"),lty=1,lwd=1)
abline(a=0, b= 1)

```




# Create another model using just the continuouspredictors and use LDA or QDA.

# LDA/QDA CODE 

## LDA Assumptions

###Assumption for equal variances between groups for each variable
```{r LDAassumptions1, fig.height=6, fig.width=10}

lda_eq_var <- function(myVar) {
ggplot(df_trainclean, aes_string(x='pay_response', y={{myVar}}, fill='pay_response')) + 
  geom_boxplot() + 
  theme(legend.position='none') +
  labs(title=paste({{myVar}}, "by pay_response", sep=' '))
}

ggarrange(lda_eq_var("age"),lda_eq_var("hours_per_week"),lda_eq_var("capital_net"),nrow=2,ncol=2)

lda_eq_var_cov <- function(myVarX, myVarY) {
ggplot(df_trainclean, aes_string(x = {{myVarX}}, y = {{myVarY}}, col = 'pay_response')) + 
    geom_point() + 
    stat_ellipse() +
    labs(title=paste({{myVarX}},'vs.',{{myVarY}},'by outcome', sep=' ')) +
    theme(legend.position='none')
}

ggarrange(lda_eq_var_cov("age","hours_per_week"),
          lda_eq_var_cov("age","capital_net"),
          lda_eq_var_cov("hours_per_week","capital_net"),
          nrow=2, ncol=3
)

```



###Normality assumption
```{r Normality Assumption}
pay.yes <- subset(df_trainclean, pay_response == ">50K") 
pay.no <- subset(df_trainclean, pay_response == "<=50K")

variable_1 <- c("age","hours_per_week", "capital_net") 
par(mfrow = c(2, 2)) 
for(i in variable_1) { 
    qqnorm(pay.yes[[i]]); qqline(pay.yes[[i]], col = 2) 
}

par(mfrow = c(2, 2)) 
for(i in variable_1) { 
    qqnorm(pay.no[[i]]); qqline(pay.no[[i]], col = 2) 
}
```

# LOG Transformation since assumptions failed for LDA with the continuous explanatory variables
### LDA LOGIC

```{r}
df_traincleanlog <- df_trainclean[, c(1, 8, 10, 11)]
df_testcleanlog <- df_testclean[, c(1, 8, 10, 11)]

df_traincleanlog$logage <-  log(df_traincleanlog$age)
df_traincleanlog$loghours_per_week <-  log(df_traincleanlog$hours_per_week)
df_traincleanlog$logcapital_net <-  log(df_traincleanlog$capital_net)

df_testcleanlog$logage <-  log(df_testcleanlog$age)
df_testcleanlog$loghours_per_week <-  log(df_testcleanlog$hours_per_week)
df_testcleanlog$logcapital_net <-  log(df_testcleanlog$capital_net)


lda_eq_var1 <- function(myVar) {
ggplot(df_traincleanlog, aes_string(x='pay_response', y={{myVar}}, fill='pay_response')) + 
  geom_boxplot() + 
  theme(legend.position='none') +
  labs(title=paste({{myVar}}, "by pay_response", sep=' '))
}

ggarrange(lda_eq_var1("logage"),lda_eq_var1("loghours_per_week"),lda_eq_var1("logcapital_net"),nrow=2,ncol=2)

lda_eq_var_cov1 <- function(myVarX, myVarY) {
ggplot(df_traincleanlog, aes_string(x = {{myVarX}}, y = {{myVarY}}, col = 'pay_response')) + 
    geom_point() + 
    stat_ellipse() +
    labs(title=paste({{myVarX}},'vs.',{{myVarY}},'by outcome', sep=' ')) +
    theme(legend.position='none')
}

ggarrange(lda_eq_var_cov1("logage","loghours_per_week"),
          lda_eq_var_cov1("logage","logcapital_net"),
          lda_eq_var_cov1("loghours_per_week","logcapital_net"),
          nrow=2, ncol=3
)

pay.yes <- subset(df_traincleanlog, pay_response == ">50K")
pay.no <- subset(df_traincleanlog, pay_response == "<=50K")
pay.tyes <- subset(df_testcleanlog, pay_response == ">50K")
pay.tno <- subset(df_testcleanlog, pay_response == "<=50K")

pay.yes <- subset(pay.yes, logcapital_net != "-Inf" )
pay.yes <- subset(pay.yes, logcapital_net != "NaN" )

pay.tyes <- subset(pay.tyes, logcapital_net != "-Inf" )
pay.tyes <- subset(pay.tyes, logcapital_net != "NaN" )

pay.no <- subset(pay.no, logcapital_net != "-Inf" )
pay.no <- subset(pay.no, logcapital_net != "NaN" )

pay.tno <- subset(pay.tno, logcapital_net != "-Inf" )
pay.tno <- subset(pay.tno, logcapital_net != "NaN" )


variable_2 <- c("logage", "loghours_per_week", "logcapital_net") 
par(mfrow = c(2, 2)) 
for(i in variable_2) { 
    qqnorm(pay.yes[[i]]); qqline(pay.yes[[i]], col = 2) 
}

par(mfrow = c(2, 2)) 
for(i in variable_1) { 
    qqnorm(pay.no[[i]]); qqline(pay.no[[i]], col = 2) 
}

# what we need for LDA is that the point clouds for the two response categories should have similar elliptical shapes. Gross departures from this would require the use of QDA instead.
#Conclusion - we'll run QDA for our project.

```

# LDA Code for Logs
```{r}
df_traincleanlogx <- rbind(pay.yes, pay.no)
df_testcleanlogx <- rbind(pay.tyes, pay.tno)
#view(df_traincleanlogx)
lda.fit = lda(pay_response~., data = df_traincleanlogx[,c(3,5,6,7)])

lda.fit

##Predict Training Results
predmodel.train.ldax <-  predict(lda.fit, data=df_traincleanlogx)
predmodel.train.ldax

# Create table to get prediction accuracy
table(Predicted <- predmodel.train.ldax$class, pay_response = df_traincleanlogx$pay_response)
conf_matrix_train <-  table(Predicted <- predmodel.train.ldax$class, pay_response = df_traincleanlogx$pay_response)

sensitivity(conf_matrix_train)
specificity(conf_matrix_train)


# print out histogram to show split
ldahist(predmodel.train.ldax$x[,1], g= predmodel.train.ldax$class)

#Test
predmodel.test.ldax = predict(lda.fit, newdata=df_testcleanlogx)
table(Predicted=predmodel.test.ldax$class, pay_response=df_testcleanlogx$pay_response)

conf_matrix_test <- table(Predicted=predmodel.test.ldax$class, pay_response=df_testcleanlogx$pay_response)

cm_test <-  confusionMatrix(conf_matrix_test, positive = "<=50K")
cm_test


#ROC for LDA
preds <- predmodel.test.ldax$posterior
preds <- as.data.frame(preds)

pred <- prediction(preds[,2],df_testcleanlogx$pay_response)
roc.lda = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.lda)
abline(a=0, b= 1)


```

#QDA

```{r}
qda.fit = qda(pay_response~., data = df_traincleanlogx[,c(3,5,6,7)])

qda.fit

##Predict Training Results
predmodel.train.qdax <-  predict(qda.fit, data=df_traincleanlogx)
predmodel.train.qdax

# Create table to get prediction accuracy
table(Predicted <- predmodel.train.qdax$class, pay_response = df_traincleanlogx$pay_response)
conf_matrix_train <-  table(Predicted <- predmodel.train.qdax$class, pay_response = df_traincleanlogx$pay_response)

sensitivity(conf_matrix_train)
specificity(conf_matrix_train)


# print out histogram to show split
#ldahist(predmodel.train.qdax$x[,1], g= predmodel.train.qdax$class)

#Test
predmodel.test.qdax = predict(qda.fit, newdata=df_testcleanlogx)
table(Predicted=predmodel.test.qdax$class, pay_response=df_testcleanlogx$pay_response)

conf_matrix_test <- table(Predicted=predmodel.test.qdax$class, pay_response=df_testcleanlogx$pay_response)

cm_test <-  confusionMatrix(conf_matrix_test, positive = ">50K")
cm_test


#ROC for QDA
preds <- predmodel.test.qdax$posterior
preds <- as.data.frame(preds)

pred <- prediction(preds[,2],df_testcleanlogx$pay_response)
roc.qda = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.qda)
abline(a=0, b= 1)


```

###Final ROC for outputs
```{r}
plot(roc.lda)
plot(roc.qda, col ="red", add = TRUE)
plot(roc.lasso,col="green", add = TRUE)
plot(roc.step,col="orange", add = TRUE)
legend("bottomright",legend=c("LDA","QDA","Lasso","Stepwise"),col=c("black","red","green", "orange"),lty=1,lwd=1)
abline(a=0, b= 1)

```





